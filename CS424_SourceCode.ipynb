{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUTV5r_oEW4f",
        "outputId": "49a5601e-1fdb-45b6-8bb3-d22da14b1999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIV_OP: /\n",
            "DIV_OP: /\n",
            "IDENTIFIER: Simple\n",
            "IDENTIFIER: addition\n",
            "IDENTIFIER: a\n",
            "ASSIGN_OP: =\n",
            "LITERAL_INT: 5\n",
            "ADD_OP: +\n",
            "LITERAL_INT: 3\n",
            "KEYWORD: print\n",
            "IDENTIFIER: a\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "class TokenType:\n",
        "    KEYWORD = 'KEYWORD'\n",
        "    IDENTIFIER = 'IDENTIFIER'\n",
        "    LITERAL_INT = 'LITERAL_INT'\n",
        "    LITERAL_BOOL = 'LITERAL_BOOL'\n",
        "    ADD_OP = 'ADD_OP'\n",
        "    SUB_OP = 'SUB_OP'\n",
        "    MUL_OP = 'MUL_OP'\n",
        "    DIV_OP = 'DIV_OP'\n",
        "    EQ_OP = 'EQ_OP'\n",
        "    ASSIGN_OP = 'ASSIGN_OP'\n",
        "    NEQ_OP = 'NEQ_OP'\n",
        "    ERROR = 'ERROR'\n",
        "    NEWLINE = 'NEWLINE'\n",
        "\n",
        "class Token:\n",
        "    def __init__(self, token_type, lexeme):\n",
        "        self.token_type = token_type\n",
        "        self.lexeme = lexeme\n",
        "\n",
        "class Scanner:\n",
        "    def __init__(self, source_code):\n",
        "        self.source_code = source_code\n",
        "        self.current_index = 0\n",
        "        self.keywords = {'if', 'else', 'print', 'true', 'false'}\n",
        "\n",
        "    def scan_tokens(self):\n",
        "        tokens = []\n",
        "\n",
        "        while self.current_index < len(self.source_code):\n",
        "            char = self.source_code[self.current_index]\n",
        "\n",
        "            if char.isdigit():\n",
        "                tokens.append(self.scan_literal_int())\n",
        "            elif char.isalpha():\n",
        "                tokens.append(self.scan_identifier_or_keyword())\n",
        "            elif char == '+':\n",
        "                tokens.append(Token(TokenType.ADD_OP, char))\n",
        "                self.current_index += 1\n",
        "            elif char == '-':\n",
        "                tokens.append(Token(TokenType.SUB_OP, char))\n",
        "                self.current_index += 1\n",
        "            elif char == '*':\n",
        "                tokens.append(Token(TokenType.MUL_OP, char))\n",
        "                self.current_index += 1\n",
        "            elif char == '/':\n",
        "                tokens.append(Token(TokenType.DIV_OP, char))\n",
        "                self.current_index += 1\n",
        "            elif char == '=':\n",
        "                if self.peek_next() == '=':\n",
        "                    tokens.append(Token(TokenType.EQ_OP, '=='))\n",
        "                    self.current_index += 2\n",
        "                else:\n",
        "                    tokens.append(Token(TokenType.ASSIGN_OP, char))\n",
        "                    self.current_index += 1\n",
        "            elif char == '!':\n",
        "                if self.peek_next() == '=':\n",
        "                    tokens.append(Token(TokenType.NEQ_OP, '!='))\n",
        "                    self.current_index += 2\n",
        "                else:\n",
        "                    self.report_error(\"Unexpected character '!'\")\n",
        "                    self.current_index += 1\n",
        "            elif char.isspace():\n",
        "                self.current_index += 1\n",
        "            elif char == '\\n':\n",
        "                tokens.append(Token(TokenType.NEWLINE, char))\n",
        "                self.current_index += 1\n",
        "            elif char == '/':\n",
        "                if self.peek_next() == '/':\n",
        "                    self.skip_comment()\n",
        "                else:\n",
        "                    self.report_error(\"Unexpected character '/'\")\n",
        "                    self.current_index += 1\n",
        "            else:\n",
        "                self.report_error(f\"Invalid character '{char}'\")\n",
        "                self.current_index += 1\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def scan_literal_int(self):\n",
        "        start_index = self.current_index\n",
        "        while self.current_index < len(self.source_code) and self.source_code[self.current_index].isdigit():\n",
        "            self.current_index += 1\n",
        "        lexeme = self.source_code[start_index:self.current_index]\n",
        "        return Token(TokenType.LITERAL_INT, lexeme)\n",
        "\n",
        "    def scan_identifier_or_keyword(self):\n",
        "        start_index = self.current_index\n",
        "        while self.current_index < len(self.source_code) and (self.source_code[self.current_index].isalnum() or self.source_code[self.current_index] == '_'):\n",
        "            self.current_index += 1\n",
        "        lexeme = self.source_code[start_index:self.current_index]\n",
        "        token_type = TokenType.KEYWORD if lexeme in self.keywords else TokenType.IDENTIFIER\n",
        "        return Token(token_type, lexeme)\n",
        "\n",
        "    def peek_next(self):\n",
        "        if self.current_index + 1 < len(self.source_code):\n",
        "            return self.source_code[self.current_index + 1]\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def skip_comment(self):\n",
        "        while self.current_index < len(self.source_code) and self.source_code[self.current_index] != '\\n':\n",
        "            self.current_index += 1\n",
        "\n",
        "    def report_error(self, message):\n",
        "        print(f\"Lexical error: {message} at position {self.current_index}\")\n",
        "\n",
        "# Example usage:\n",
        "source_code = \"\"\"\n",
        "// Simple addition\n",
        "a = 5 + 3\n",
        "print a\n",
        "\"\"\"\n",
        "scanner = Scanner(source_code)\n",
        "tokens = scanner.scan_tokens()\n",
        "\n",
        "for token in tokens:\n",
        "    print(f\"{token.token_type}: {token.lexeme}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4QD3Dy8FcYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}